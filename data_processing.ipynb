{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are by far the most prevalent keys in the corpus, so we're going to restrict ourselves to\n",
    "# pieces in these keys\n",
    "KEYS = ['A', 'C', 'D', 'F', 'G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likewise, most pieces have 4, 5, or 6 voices\n",
    "VOICES = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIECES = music21.corpus.getComposer('palestrina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pieces_generator(pieces: [str]=PIECES) -> Iterator[music21.stream.Score]:\n",
    "    return (music21.corpus.parse(piece) for piece in pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_voices(score: music21.stream.Score) -> int:\n",
    "    return len(score.getElementsByClass(music21.stream.Part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(score: music21.stream.Score) -> str:\n",
    "    return score.analyze('key').tonic.fullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_include(score: music21.stream.Score, keys: [str]=KEYS, voices: [int]=VOICES) -> bool:\n",
    "    return get_key(score) in keys and n_voices(score) in voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_to_all_keys_gen(score: music21.stream.Score, keys: [str]=KEYS) -> Generator[music21.stream.Score, None, None]:\n",
    "    for key in keys:\n",
    "        score_key = score.analyze('key')\n",
    "        if score_key.tonic.fullName == key:\n",
    "            yield score\n",
    "        else:\n",
    "            interval = music21.interval.Interval(score_key.tonic, music21.pitch.Pitch(key))\n",
    "            yield score.transpose(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_shape(score: music21.stream.Score) -> (int, int):\n",
    "    n_voices: int = len(score.getElementsByClass(music21.stream.Part))\n",
    "    n_eighth_notes: int = int(score.duration.quarterLength * 2)\n",
    "    return n_voices, n_eighth_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_slur = 0\n",
    "idx_rest = 1\n",
    "idx_beat = 2\n",
    "max_beats_per_measure = 16\n",
    "n_meta_features = 18\n",
    "\n",
    "def score_to_tensor(score: music21.stream.Score) -> (np.ndarray, np.ndarray):\n",
    "    n_voices, n_eighths = get_score_shape(score)\n",
    "    score_tensor = np.zeros((n_voices, n_eighths))\n",
    "    meta_tensor = np.zeros((n_voices, n_eighths, n_meta_features))\n",
    "    max_beats_per_measure\n",
    "    try:\n",
    "        for i, part in enumerate(score.getElementsByClass(music21.stream.Part)):\n",
    "            for measure in part.getElementsByClass(music21.stream.Measure):\n",
    "                # we're going to multiply all durations by two,\n",
    "                # because eighth note is the shortest in the corpus.\n",
    "                beats_in_measure = measure.duration.quarterLength * 2\n",
    "                # Get the offset of the beginning of the measure (from the beginning of the piece)\n",
    "                measure_offset = int(measure.offset)\n",
    "                for b in range(int(beats_in_measure)):\n",
    "                    # Annotate each eighth-note pulse in the metadata track\n",
    "                    meta_tensor[i][measure_offset * 2 + b][idx_beat + b] = 1\n",
    "                for note in measure.getElementsByClass(music21.note.Note):\n",
    "                    offset = int(note.offset + measure_offset) * 2\n",
    "                    for j in range(int(offset), int(offset + note.duration.quarterLength * 2)):\n",
    "                        # mark the note with its midi pitch throughout its duration\n",
    "                        score_tensor[i, j] = float(note.midi)\n",
    "                        if j > offset:\n",
    "                            # Add a 'slur' annotation for any held note\n",
    "                            meta_tensor[i, j, idx_slur] = 1\n",
    "                for rest in measure.getElementsByClass(music21.note.Rest):\n",
    "                    # Mark all rests in the metadata track\n",
    "                    offset = int(rest.offset + measure_offset) * 2\n",
    "                    for j in range(int(offset), int(offset + rest.duration.quarterLength * 2)):\n",
    "                        meta_tensor[i, j, idx_rest] = 1\n",
    "        return score_tensor, meta_tensor  \n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1318 out of 1318 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "scores = Parallel(n_jobs=-1, verbose=5)(delayed(music21.corpus.parse)(piece)\n",
    "    for piece in PIECES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1318/1318 [02:45<00:00,  7.97it/s]\n"
     ]
    }
   ],
   "source": [
    "included_scores = [score for score in tqdm(scores) if should_include(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(included_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [1:24:35<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "transposed_scores = [\n",
    "    transposed\n",
    "    for score in tqdm(included_scores)\n",
    "    for transposed in transpose_to_all_keys_gen(score)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('score_tensors.pkl', 'w+b') as scores_file:\n",
    "# #     pickle.dump(score_tensors, scores_file)\n",
    "#     scores_file.write(b'foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [41:36<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "score_tensors = [\n",
    "    score_to_tensor(score)\n",
    "    for score in tqdm(transposed_scores)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5930it [00:05, 1086.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, score in tqdm(enumerate(score_tensors)):\n",
    "    tensor, meta = score\n",
    "    np.save('./data/{}.npy'.format(i), tensor)\n",
    "    np.save('./data/{}_meta.npy'.format(i), meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:39<00:00, 149.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# save a list of the names of the scores\n",
    "score_names = [list(score)[0].title + \" - \" + list(score)[0].parentTitle for score in tqdm(transposed_scores)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/score_names.npy', score_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, meta = score_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t, _ in score_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pitch = np.min([np.min(t[t > 0]) for t, _ in score_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = int(max_pitch - min_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sequence, meta_sequence = make_input_sequence_for_voice(padded_score, padded_meta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 720, 32, 5, 1)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([score_sequence]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_target, meta_target = make_targets_for_voice(score, meta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 720, 57)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([make_input_sequence_for_voice()]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model attempt # 1: do not incorporate metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 4269/5930 [03:20<01:17, 21.31it/s]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([\n",
    "    make_targets_for_voice(score, meta, voice)[0]\n",
    "    for score, meta in tqdm(score_tensors)\n",
    "    for voice in range(score.shape[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
