{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:01<00:00, 3054.40it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch)\n",
    "            y[i, note_idx] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_meta(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    y_meta = np.zeros((meta.shape[1], 2)) #  add 2 meta features: slur, rest\n",
    "    for i in range(meta.shape[1]):\n",
    "        y_meta[i, idx_rest] = meta[voice, i, idx_rest]\n",
    "        y_meta[i, idx_slur] = meta[voice, i, idx_slur]\n",
    "    return y_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "    max_voices = 6\n",
    "    voices_padding_size = max_voices - score.shape[0]\n",
    "    voices_padding = np.zeros((voices_padding_size, score.shape[1]))\n",
    "    voices_padded = np.vstack((score, voices_padding))\n",
    "    score_padding = np.zeros((max_voices, padding_size))\n",
    "    return np.hstack((score_padding, voices_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_meta(meta, window_size):\n",
    "    padding_size = window_size - 1\n",
    "    meta_padding = np.zeros((meta.shape[0], padding_size, meta.shape[2]))\n",
    "    return np.hstack((meta_padding, meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, voice, window_size=96, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    padded_score = make_padded(score, window_size)\n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    score_sequence = padded_score.T[indexer, :, None]\n",
    "\n",
    "    # Now, mask out the target values\n",
    "    score_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return score_sequence.reshape((score.shape[1], 3, conv_window_size, padded_score.shape[0], 1)) / max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence_meta(meta, voice, window_size=96, conv_window_size=32):\n",
    "    padded_meta = make_padded_meta(meta, window_size)\n",
    "    \n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    meta_sequence = np.swapaxes(padded_meta, 0, 1)[indexer, :, :]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    meta_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return meta_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid = train_test_split(scores, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 208)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = itertools.cycle(\n",
    "    (make_input_sequence(score, voice), make_targets(score, voice))\n",
    "    for score in scores_train\n",
    "    for voice in range(score.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = itertools.cycle(\n",
    "    (make_input_sequence(score, voice), make_targets(score, voice))\n",
    "    for score in scores_valid\n",
    "    for voice in range(score.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 3, 32, 6, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_gen)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Conv2D, TimeDistributed, Input, Activation, Flatten, LSTM, ConvLSTM2D, Dense, Dropout, MaxPool2D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "from keras.activations import relu\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 32\n",
    "n_features = 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 3, 32, 6, 32)      320       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 3, 16, 3, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 3, 16, 3, 32)      9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 3, 8, 2, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 3, 8, 2, 64)       18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 3, 4, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 3, 4, 1, 128)      73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 3, 4, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               25800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 58)                11658     \n",
      "=================================================================\n",
      "Total params: 270,962\n",
      "Trainable params: 270,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model=Sequential()\n",
    "# model.add(ConvLSTM2D(32, 3, padding='same', activation='relu', return_sequences=True, input_shape=(1, window_size, None, 1)))\n",
    "# model.add(ConvLSTM2D(64, 3, strides=2, padding='same', activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(n_features, activation='softmax'))\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "#### MODEL 1\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu'), input_shape=(1, window_size, 6, 1)))\n",
    "# model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "# model.add(TimeDistributed(Conv2D(64, 3, padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed(Conv2D(64, 3, padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "# model.add(TimeDistributed(Dropout(0.1)))\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(LSTM(128, activation='relu'))\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(n_features, activation='softmax'))\n",
    "\n",
    "#### MODEL 2\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu'), input_shape=(3, window_size, 6, 1)))\n",
    "model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(64, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(128, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.1)))\n",
    "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(n_features, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model2.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.sum(score.shape[0] for score in scores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps = np.sum(score.shape[0] for score in scores_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./models/model2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16602/25419 [==================>...........] - ETA: 9:31 - loss: 1.0678 - acc: 0.4821"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
