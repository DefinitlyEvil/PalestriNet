{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:02<00:00, 2845.69it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:04<00:00, 1444.04it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = [\n",
    "    (np.load('./data/{}_meta.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is a stream of notes and rests for one voice.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes + 1  # all possible notes plus rest\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch) + 1\n",
    "            y[i, note_idx] = 1\n",
    "        else:\n",
    "            y[i, 0] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SEQUENCE_STEPS = 3\n",
    "window_size = 32\n",
    "n_features = 58\n",
    "BATCH_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_slur = 0\n",
    "idx_beat = 2\n",
    "\n",
    "def make_targets_slur(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    return meta[voice, :, idx_slur].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size, max_voices=6):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "    if max_voices is not None:\n",
    "\n",
    "        voices_padding_size = max_voices - score.shape[0]\n",
    "        voices_padding = np.zeros((voices_padding_size, score.shape[1]))\n",
    "        score = np.vstack((score, voices_padding))\n",
    "        score_padding = np.zeros((max_voices, padding_size))\n",
    "    else:\n",
    "        score_padding = np.zeros((score.shape[0], padding_size))\n",
    "    return np.hstack((score_padding, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, voice, sequence_steps=16, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    padded_score = make_padded(score, window_size)\n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    score_sequence = padded_score.T[indexer, :, None]\n",
    "\n",
    "    # Now, mask out the target values\n",
    "    score_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return score_sequence.reshape((score.shape[1], -1, conv_window_size, padded_score.shape[0], 1)) / max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence_slur(meta, voice, sequence_steps=16, conv_window_size=32):\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    padded_meta = make_padded(meta[:, :, idx_slur], window_size)\n",
    "    \n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_meta.shape[1] - padding_size)[:, None]\n",
    "    slur_sequence = padded_meta.T[indexer, :, None]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    slur_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return slur_sequence.reshape((meta.shape[1], -1, conv_window_size, padded_meta.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence_beat(meta, voice=0, window_size=SEQUENCE_STEPS):\n",
    "    padding = np.zeros((meta.shape[0], window_size - 1, meta.shape[2]))\n",
    "    padded = np.hstack([padding, meta])\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(meta.shape[1])[:, None]\n",
    "    return np.squeeze(padded[voice, :, idx_beat:][indexer, :, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid, meta_train, meta_valid = train_test_split(scores, meta, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 3, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(make_input_sequence_beat(meta_valid[2], 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 16, 32, 6, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([\n",
    "    make_input_sequence(scores_valid[2], 0),\n",
    "    make_input_sequence_slur(meta_valid[2], 0)\n",
    "], axis=4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(scores, meta):\n",
    "    for score, meta in zip(scores_train, meta_train):\n",
    "        for voice in range(score.shape[0]):\n",
    "            # inputs\n",
    "            notes = make_input_sequence(score, voice, sequence_steps=SEQUENCE_STEPS)\n",
    "            slurs = make_input_sequence_slur(meta, voice, sequence_steps=SEQUENCE_STEPS)\n",
    "            notes_slurs = np.concatenate((notes, slurs), axis=4)\n",
    "            beats = make_input_sequence_beat(meta, voice)\n",
    "            # targets\n",
    "            note_targets = make_targets(score, voice)\n",
    "            slur_targets = make_targets_slur(meta, voice)\n",
    "            for i in range(0, score.shape[1], BATCH_LENGTH):\n",
    "                yield (\n",
    "                    [\n",
    "                        notes_slurs[i:i+BATCH_LENGTH],\n",
    "                        beats[i:i+BATCH_LENGTH],\n",
    "                    ],\n",
    "                    [\n",
    "                        note_targets[i:i+BATCH_LENGTH],\n",
    "                        slur_targets[i:i+BATCH_LENGTH],\n",
    "                    ]\n",
    "                )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = cycle(data_gen(scores_train, meta_train))\n",
    "valid_gen = cycle(data_gen(scores_valid, meta_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = cycle(\n",
    "#     ([\n",
    "#         make_input_sequence(score, voice, sequence_steps=SEQUENCE_STEPS),\n",
    "#         make_input_sequence_slur(meta[:, i:i+BATCH_LENGTH, :], voice, sequence_steps=SEQUENCE_STEPS),\n",
    "#         make_input_sequence_beat(meta[:, i:i+BATCH_LENGTH, :], voice),\n",
    "#     ], [\n",
    "#         make_targets(score[:, i:i+BATCH_LENGTH], voice),\n",
    "#         make_targets_slur(meta[:, i:i+BATCH_LENGTH, :], voice)\n",
    "#     ])\n",
    "#     for score, meta in zip(scores_train, meta_train)\n",
    "#     for voice in range(score.shape[0])\n",
    "#     for i in range(0, score.shape[1], BATCH_LENGTH)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_gen = cycle(\n",
    "#     ([\n",
    "#         make_input_sequence(score[:, i:i+BATCH_LENGTH], voice, sequence_steps=SEQUENCE_STEPS),\n",
    "#         make_input_sequence_slur(meta[:, i:i+BATCH_LENGTH, :], voice, sequence_steps=SEQUENCE_STEPS),\n",
    "#         make_input_sequence_beat(meta[:, i:i+BATCH_LENGTH, :], voice),\n",
    "#     ], [\n",
    "#         make_targets(score[:, i:i+BATCH_LENGTH], voice),\n",
    "#         make_targets_slur(meta[:, i:i+BATCH_LENGTH, :], voice)\n",
    "#     ])\n",
    "#     for score, meta in zip(scores_valid, meta_valid)\n",
    "#     for voice in range(score.shape[0])\n",
    "#     for i in range(0, score.shape[1], BATCH_LENGTH)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 16, 32, 6, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence_slur(meta_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Conv2D, TimeDistributed, Input, Activation, Flatten, LSTM, CuDNNLSTM, ConvLSTM2D, Dense, Dropout, MaxPooling2D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "from keras.activations import relu\n",
    "import keras.callbacks\n",
    "from keras.layers import add, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, nb_filters):\n",
    "    skip = Conv2D(nb_filters, (1, 1))(input_layer)\n",
    "    \n",
    "    layer_1 = Conv2D(nb_filters, (3, 3), padding=\"same\")(input_layer)\n",
    "    layer_1_bn = BatchNormalization()(layer_1)\n",
    "    layer_1_a = Activation(\"relu\")(layer_1_bn)\n",
    "    \n",
    "    layer_2 = Conv2D(nb_filters, (3, 3), padding=\"same\")(layer_1_a)\n",
    "    layer_2_bn = BatchNormalization()(layer_2)\n",
    "    \n",
    "    combined = add([skip, layer_2_bn])\n",
    "    return Activation(\"relu\")(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convnet(input_layer):\n",
    "    a1 = residual_block(input_layer, 32)\n",
    "    a2 = MaxPooling2D(2, (2, 2), padding=\"same\")(a1)\n",
    "    \n",
    "    b1 = residual_block(a2, 64)\n",
    "    return GlobalAveragePooling2D()(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 3, 32, 6, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 3, 16)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 3, 64)        68256       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 3, 32)        544         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 96)        0           time_distributed_1[0][0]         \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 3, 64)        41216       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           33024       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 59)           3835        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 146,940\n",
      "Trainable params: 146,556\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make the input networks\n",
    "input_notes = Input(shape=(window_size, 6, 2))\n",
    "notes_convnet = make_convnet(input_notes)\n",
    "\n",
    "notes_model = Model(inputs=[input_notes], outputs=[notes_convnet])\n",
    "\n",
    "input_beats = (Input(shape=(16,)))\n",
    "beats_net = Dense(32, activation='relu')(input_beats)\n",
    "beats_model = Model(inputs=[input_beats], outputs=[beats_net])\n",
    "\n",
    "\n",
    "# Make the sequence/timedistributed versions of them\n",
    "input_notes_sequence = Input(shape=(SEQUENCE_STEPS, window_size, 6, 2))\n",
    "notes = TimeDistributed(notes_model)(input_notes_sequence)\n",
    "\n",
    "input_beats_sequence = Input(shape=(SEQUENCE_STEPS, 16))\n",
    "beats = TimeDistributed(beats_model)(input_beats_sequence)\n",
    "\n",
    "lstm_input = concatenate([notes, beats])\n",
    "\n",
    "lstm_1 = LSTM(64, dropout=0.1, return_sequences=True)(lstm_input)\n",
    "lstm_2 = LSTM(64, dropout=0.1)(lstm_1)\n",
    "\n",
    "# Add information about beat\n",
    "\n",
    "\n",
    "# make outputs\n",
    "output_notes = Dense(n_features + 1, activation='softmax')(lstm_2)\n",
    "output_slurs = Dense(1, activation='sigmoid')(lstm_2)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[input_notes_sequence, input_beats_sequence],\n",
    "    outputs=[output_notes, output_slurs]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=['categorical_crossentropy', 'binary_crossentropy'], metrics=['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model-multi.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152825"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = np.sum(score.shape[0] * score.shape[1] // BATCH_LENGTH for score in scores_train)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7685"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_steps = np.sum(score.shape[0] * score.shape[1] // BATCH_LENGTH for score in scores_valid)\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('./models/model-multi.hdf5')\n",
    "except OSError:\n",
    "    print('no weights found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   785/152825 [..............................] - ETA: 2:46:34 - loss: 1.0250 - dense_2_loss: 0.8894 - dense_3_loss: 0.1357 - dense_2_acc: 0.7056 - dense_2_top3_acc: 0.9055 - dense_3_acc: 0.9436 - dense_3_top3_acc: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=500,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_gen, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_valid[0][0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
