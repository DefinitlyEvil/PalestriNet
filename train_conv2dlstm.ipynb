{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:48<00:00, 121.91it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [09:24<00:00, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = [\n",
    "    (np.load('./data/{}_meta.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1\n",
    "idx_slur = 0\n",
    "idx_beat = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SEQUENCE_STEPS = 4  # The number of windows to look at; 4 * 32 means we look at an 8-bar window\n",
    "window_size = 32  # each measure is 16, so 32 is a two-measure window\n",
    "n_features = n_notes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes + 1\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch)\n",
    "            y[i, note_idx + 1] = 1\n",
    "        else:\n",
    "            y[i, 0] = 1 # it's a rest\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_slur(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    return meta[voice, :, idx_slur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size, max_voices=None):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "\n",
    "    score_padding = np.zeros((score.shape[0], padding_size))\n",
    "    return np.hstack((score_padding, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_beat(meta, voice):\n",
    "    return meta[voice, :, idx_beat:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, meta, voice, sequence_steps=16, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    # First, do the notes channel\n",
    "    padded_score = make_padded(score, window_size) / max_pitch\n",
    "    padding_size = window_size - 1\n",
    "    \n",
    "    # Now, the slurs channel\n",
    "    padded_meta = make_padded(meta[:, :, 0], window_size)\n",
    "    \n",
    "    # A mask showing which voice to predict\n",
    "    voice_mask = np.zeros(padded_meta.shape)\n",
    "    \n",
    "    # Stack them together\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    stacked = np.stack((padded_score, padded_meta, voice_mask), axis=-1)\n",
    "    \n",
    "    # Make the sliding windows\n",
    "    sequence = stacked.swapaxes(0, 1)[indexer, :, :]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    sequence[:, -1, voice, :2] = 0\n",
    "    \n",
    "    # Set a flag in the voice mask to indicate which voice is to be predicted\n",
    "    sequence[:, -1, voice, 2] = 1\n",
    "    \n",
    "    return sequence.reshape((score.shape[1], -1, conv_window_size, padded_score.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid, meta_train, meta_valid = train_test_split(scores, meta, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 16, 32, 5, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence(scores_valid[0], meta_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSequence(Sequence):\n",
    "    def __init__(self, scores, meta, subsample_voices=False):\n",
    "        self.scores = scores\n",
    "        self.meta = meta\n",
    "        if subsample_voices:\n",
    "            # Take one randomly sampled voice for each score\n",
    "            voice_sample = [\n",
    "                np.random.randint(score.shape[0]) \n",
    "                for score in scores\n",
    "            ]\n",
    "            self.indices = [\n",
    "                (score_idx, voice_sample[score_idx])\n",
    "                for score_idx, score in enumerate(scores)\n",
    "            ]\n",
    "        else:\n",
    "            self.indices = [\n",
    "                (score_idx, voice_idx)\n",
    "                for score_idx, score in enumerate(scores)\n",
    "                for voice_idx in range(score.shape[0])\n",
    "            ]\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        score_idx, voice = self.indices[idx]\n",
    "        score = self.scores[score_idx]\n",
    "        meta = self.meta[score_idx]\n",
    "        return (\n",
    "            [\n",
    "                make_input_sequence(score, meta, voice, sequence_steps=SEQUENCE_STEPS, conv_window_size=window_size),\n",
    "                make_input_beat(meta, voice)\n",
    "            ],\n",
    "            [\n",
    "                make_targets(score, voice),\n",
    "                make_targets_slur(meta, voice)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sequence = BatchSequence(scores_valid, meta_valid, subsample_voices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = BatchSequence(scores_train, meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.activations import relu\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_lst_m2d_5_input (InputLaye (None, None, 32, Non 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)     (None, None, 32, Non 40448       conv_lst_m2d_5_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, None, 16, Non 0           conv_lst_m2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)     (None, 16, None, 64) 221440      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           conv_lst_m2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80)           0           global_average_pooling2d_3[0][0] \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 80)           0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          8100        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 59)           5959        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            101         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 276,048\n",
      "Trainable params: 276,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "notes_model = Sequential()\n",
    "notes_model.add(layers.ConvLSTM2D(32, 3, return_sequences=True, padding='same', input_shape=(None, window_size, None, 3)))\n",
    "notes_model.add(layers.MaxPool3D(2, 2))\n",
    "notes_model.add(layers.ConvLSTM2D(64, 3, padding='same'))\n",
    "notes_model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "beats_input = layers.Input(shape=(16,))\n",
    "\n",
    "features = layers.concatenate([notes_model.output, beats_input])\n",
    "dropout1 = layers.Dropout(0.2)(features)\n",
    "\n",
    "fc_1 = layers.Dense(100, activation='relu')(dropout1)\n",
    "dropout2 = layers.Dropout(0.2)(fc_1)\n",
    "\n",
    "output_notes = layers.Dense(n_notes + 1, activation='softmax')(dropout2)\n",
    "output_slur = layers.Dense(1, activation='sigmoid')(fc_1)\n",
    "\n",
    "model = Model(inputs=[notes_model.input, beats_input], outputs=[output_notes, output_slur])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=['categorical_crossentropy', 'binary_crossentropy'], metrics=['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model6.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25420"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_sequence)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_steps = len(valid_sequence)\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('./models/model6.hdf5')\n",
    "except (OSError, ValueError):\n",
    "    print('no compatible weights found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.4468 - dense_2_loss: 1.2840 - dense_3_loss: 0.1628 - dense_2_acc: 0.5721 - dense_2_top3_acc: 0.8383 - dense_3_acc: 0.9296 - dense_3_top3_acc: 1.0000Epoch 00003: val_loss improved from 1.63119 to 1.20589, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9015s 355ms/step - loss: 1.4468 - dense_2_loss: 1.2840 - dense_3_loss: 0.1628 - dense_2_acc: 0.5721 - dense_2_top3_acc: 0.8383 - dense_3_acc: 0.9296 - dense_3_top3_acc: 1.0000 - val_loss: 1.2059 - val_dense_2_loss: 1.0471 - val_dense_3_loss: 0.1588 - val_dense_2_acc: 0.6711 - val_dense_2_top3_acc: 0.8911 - val_dense_3_acc: 0.9310 - val_dense_3_top3_acc: 1.0000\n",
      "Epoch 4/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.3282 - dense_2_loss: 1.1749 - dense_3_loss: 0.1532 - dense_2_acc: 0.6088 - dense_2_top3_acc: 0.8637 - dense_3_acc: 0.9328 - dense_3_top3_acc: 1.0000Epoch 00004: val_loss did not improve\n",
      "25420/25420 [==============================] - 9004s 354ms/step - loss: 1.3282 - dense_2_loss: 1.1749 - dense_3_loss: 0.1532 - dense_2_acc: 0.6088 - dense_2_top3_acc: 0.8637 - dense_3_acc: 0.9328 - dense_3_top3_acc: 1.0000 - val_loss: 1.4339 - val_dense_2_loss: 1.2800 - val_dense_3_loss: 0.1539 - val_dense_2_acc: 0.5360 - val_dense_2_top3_acc: 0.8545 - val_dense_3_acc: 0.9333 - val_dense_3_top3_acc: 1.0000\n",
      "Epoch 5/5\n",
      "21367/25420 [========================>.....] - ETA: 23:48 - loss: 1.2488 - dense_2_loss: 1.0997 - dense_3_loss: 0.1491 - dense_2_acc: 0.6349 - dense_2_top3_acc: 0.8796 - dense_3_acc: 0.9354 - dense_3_top3_acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-25:\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 391, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-16-01053d05555c>\", line 31, in __getitem__\n",
      "    make_input_sequence(score, meta, voice, sequence_steps=SEQUENCE_STEPS, conv_window_size=window_size),\n",
      "  File \"<ipython-input-28-90f5b4d0ce83>\", line 21, in make_input_sequence\n",
      "    sequence = stacked.swapaxes(0, 1)[indexer, :, :]\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d96d7dde7d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                 \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_close_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_sequence,\n",
    "    steps_per_epoch=len(train_sequence),\n",
    "    epochs=5,\n",
    "    validation_data=valid_sequence,\n",
    "    validation_steps=len(valid_sequence),\n",
    "    callbacks=[checkpointer],\n",
    "    use_multiprocessing=True,\n",
    "    initial_epoch=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.24 s, sys: 1.5 s, total: 10.7 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%time pred = model.evaluate_generator(valid_sequence, steps=250, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.5106 - dense_8_loss: 1.3444 - dense_9_loss: 0.1662 - dense_8_acc: 0.5431 - dense_8_top3_acc: 0.8214 - dense_9_acc: 0.9296 - dense_9_top3_acc: 1.0000Epoch 00001: val_loss improved from inf to 1.28242, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9084s 357ms/step - loss: 1.5106 - dense_8_loss: 1.3444 - dense_9_loss: 0.1662 - dense_8_acc: 0.5431 - dense_8_top3_acc: 0.8214 - dense_9_acc: 0.9296 - dense_9_top3_acc: 1.0000 - val_loss: 1.2824 - val_dense_8_loss: 1.1243 - val_dense_9_loss: 0.1581 - val_dense_8_acc: 0.6327 - val_dense_8_top3_acc: 0.8730 - val_dense_9_acc: 0.9301 - val_dense_9_top3_acc: 1.0000\n",
      "Epoch 2/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.3461 - dense_8_loss: 1.1892 - dense_9_loss: 0.1569 - dense_8_acc: 0.5990 - dense_8_top3_acc: 0.8617 - dense_9_acc: 0.9326 - dense_9_top3_acc: 1.0000Epoch 00002: val_loss improved from 1.28242 to 1.09103, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9047s 356ms/step - loss: 1.3461 - dense_8_loss: 1.1892 - dense_9_loss: 0.1569 - dense_8_acc: 0.5990 - dense_8_top3_acc: 0.8617 - dense_9_acc: 0.9326 - dense_9_top3_acc: 1.0000 - val_loss: 1.0910 - val_dense_8_loss: 0.9388 - val_dense_9_loss: 0.1522 - val_dense_8_acc: 0.7070 - val_dense_8_top3_acc: 0.9090 - val_dense_9_acc: 0.9339 - val_dense_9_top3_acc: 1.0000\n",
      "Epoch 3/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.2514 - dense_8_loss: 1.0996 - dense_9_loss: 0.1518 - dense_8_acc: 0.6315 - dense_8_top3_acc: 0.8808 - dense_9_acc: 0.9350 - dense_9_top3_acc: 1.0000Epoch 00003: val_loss improved from 1.09103 to 1.07514, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9092s 358ms/step - loss: 1.2513 - dense_8_loss: 1.0995 - dense_9_loss: 0.1518 - dense_8_acc: 0.6316 - dense_8_top3_acc: 0.8808 - dense_9_acc: 0.9350 - dense_9_top3_acc: 1.0000 - val_loss: 1.0751 - val_dense_8_loss: 0.9270 - val_dense_9_loss: 0.1482 - val_dense_8_acc: 0.6907 - val_dense_8_top3_acc: 0.9135 - val_dense_9_acc: 0.9350 - val_dense_9_top3_acc: 1.0000\n",
      "Epoch 4/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.1865 - dense_8_loss: 1.0385 - dense_9_loss: 0.1480 - dense_8_acc: 0.6544 - dense_8_top3_acc: 0.8913 - dense_9_acc: 0.9366 - dense_9_top3_acc: 1.0000Epoch 00004: val_loss improved from 1.07514 to 0.96548, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9126s 359ms/step - loss: 1.1864 - dense_8_loss: 1.0385 - dense_9_loss: 0.1480 - dense_8_acc: 0.6544 - dense_8_top3_acc: 0.8913 - dense_9_acc: 0.9366 - dense_9_top3_acc: 1.0000 - val_loss: 0.9655 - val_dense_8_loss: 0.8202 - val_dense_9_loss: 0.1453 - val_dense_8_acc: 0.7483 - val_dense_8_top3_acc: 0.9170 - val_dense_9_acc: 0.9374 - val_dense_9_top3_acc: 1.0000\n",
      "Epoch 5/5\n",
      " 7522/25420 [=======>......................] - ETA: 1:46:58 - loss: 1.1521 - dense_8_loss: 1.0055 - dense_9_loss: 0.1466 - dense_8_acc: 0.6669 - dense_8_top3_acc: 0.8962 - dense_9_acc: 0.9369 - dense_9_top3_acc: 1.0000"
     ]
    }
   ],
   "source": [
    "history2 = model.fit_generator(\n",
    "    train_sequence,\n",
    "    steps_per_epoch=len(train_sequence),\n",
    "    epochs=5,\n",
    "    validation_data=valid_sequence,\n",
    "    validation_steps=len(valid_sequence),\n",
    "    callbacks=[checkpointer],\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./models/model6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_pred = np.argmax(pred[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.argmax(valid_sequence[0][1][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes + (notes > 1) * (min_pitch - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_valid[0][2] - (notes + (notes > 1) * (min_pitch - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
