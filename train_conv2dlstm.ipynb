{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:09<00:00, 631.28it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [08:36<00:00, 11.48it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = [\n",
    "    (np.load('./data/{}_meta.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1\n",
    "idx_slur = 0\n",
    "idx_beat = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SEQUENCE_STEPS = 4  # The number of windows to look at; 4 * 32 means we look at an 8-bar window\n",
    "window_size = 32  # each measure is 16, so 32 is a two-measure window\n",
    "n_features = n_notes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes + 1\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch)\n",
    "            y[i, note_idx + 1] = 1\n",
    "        else:\n",
    "            y[i, 0] = 1 # it's a rest\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_slur(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    return meta[voice, :, idx_slur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size, max_voices=None):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "\n",
    "    score_padding = np.zeros((score.shape[0], padding_size))\n",
    "    return np.hstack((score_padding, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_beat(meta, voice):\n",
    "    return meta[voice, :, idx_beat:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, meta, voice, sequence_steps=16, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    # First, do the notes channel\n",
    "    padded_score = make_padded(score, window_size) / max_pitch\n",
    "    padding_size = window_size - 1\n",
    "    \n",
    "    # Now, the slurs channel\n",
    "    padded_meta = make_padded(meta[:, :, 0], window_size)\n",
    "    \n",
    "    # Stack them together\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    stacked = np.stack((padded_score, padded_meta), axis=-1)\n",
    "    \n",
    "    # Make the sliding windows\n",
    "    sequence = stacked.swapaxes(0, 1)[indexer, :, :]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return sequence.reshape((score.shape[1], -1, conv_window_size, padded_score.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid, meta_train, meta_valid = train_test_split(scores, meta, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 16, 32, 5, 2)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence_2(scores_valid[0], meta_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence(scores_valid[0], meta_valid[0], 0).shape == make_input_sequence_2(scores_valid[0], meta_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = cycle(\n",
    "    (\n",
    "        [\n",
    "            make_input_sequence(score, meta, voice, sequence_steps=SEQUENCE_STEPS, conv_window_size=window_size),\n",
    "            make_input_beat(meta, voice)\n",
    "        ],\n",
    "        [\n",
    "            make_targets(score, voice),\n",
    "            make_targets_slur(meta, voice)\n",
    "        ]\n",
    "    )\n",
    "    for score, meta in zip(scores_train, meta_train)\n",
    "    for voice in range(score.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 720, 18)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_sample_valid = [\n",
    "    np.random.randint(score.shape[0]) \n",
    "    for score in scores_valid\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSequence(Sequence):\n",
    "    def __init__(self, scores, meta, subsample_voices=False):\n",
    "        self.scores = scores\n",
    "        self.meta = meta\n",
    "        if subsample_voices:\n",
    "            # Take one randomly sampled voice for each score\n",
    "            voice_sample = [\n",
    "                np.random.randint(score.shape[0]) \n",
    "                for score in scores\n",
    "            ]\n",
    "            self.indices = [\n",
    "                (score_idx, voice_sample[score_idx])\n",
    "                for score_idx, score in enumerate(scores)\n",
    "            ]\n",
    "        else:\n",
    "            self.indices = [\n",
    "                (score_idx, voice_idx)\n",
    "                for score_idx, score in enumerate(scores)\n",
    "                for voice_idx in range(score.shape[0])\n",
    "            ]\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        score_idx, voice = self.indices[idx]\n",
    "        score = self.scores[score_idx]\n",
    "        meta = self.meta[score_idx]\n",
    "        return (\n",
    "            [\n",
    "                make_input_sequence(score, meta, voice, sequence_steps=SEQUENCE_STEPS, conv_window_size=window_size),\n",
    "                make_input_beat(meta, voice)\n",
    "            ],\n",
    "            [\n",
    "                make_targets(score, voice),\n",
    "                make_targets_slur(meta, voice)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sequence = BatchSequence(scores_valid, meta_valid, subsample_voices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = BatchSequence(scores_train, meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.activations import relu\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "conv_lst_m2d_3_input (InputLayer (None, None, 32, None 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)      (None, None, 32, None 39296       conv_lst_m2d_3_input[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)   (None, None, 16, None 0           conv_lst_m2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)      (None, 16, None, 64)  221440      max_pooling3d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 64)            0           conv_lst_m2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 16)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 80)            0           global_average_pooling2d_2[0][0] \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 100)           8100        concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 59)            5959        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             101         dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 274,896\n",
      "Trainable params: 274,896\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "notes_model = Sequential()\n",
    "notes_model.add(layers.ConvLSTM2D(32, 3, return_sequences=True, padding='same', input_shape=(None, window_size, None, 2)))\n",
    "notes_model.add(layers.MaxPool3D(2, 2))\n",
    "notes_model.add(layers.ConvLSTM2D(64, 3, padding='same'))\n",
    "notes_model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "beats_input = layers.Input(shape=(16,))\n",
    "\n",
    "features = layers.concatenate([notes_model.output, beats_input])\n",
    "\n",
    "fc_1 = layers.Dense(100, activation='relu')(features)\n",
    "dropout = layers.Dropout(0.1)(fc_1)\n",
    "\n",
    "output_notes = layers.Dense(n_notes + 1, activation='softmax')(dropout)\n",
    "output_slur = layers.Dense(1, activation='sigmoid')(fc_1)\n",
    "\n",
    "model = Model(inputs=[notes_model.input, beats_input], outputs=[output_notes, output_slur])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=['categorical_crossentropy', 'binary_crossentropy'], metrics=['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model6.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25420"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = np.sum(score.shape[0] for score in scores_train)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2835"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_steps = np.sum(score.shape[0] for score in scores_valid)\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('./models/model6.hdf5')\n",
    "except OSError:\n",
    "    print('no weights found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_sequence,\n",
    "    steps_per_epoch=len(train_sequence),\n",
    "    epochs=5,\n",
    "    validation_data=valid_sequence,\n",
    "    validation_steps=len(valid_sequence),\n",
    "    callbacks=[checkpointer],\n",
    "    use_multiprocessing=True,\n",
    "    max_queue_size=100,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 10.2 s, total: 27 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%time pred = model.predict_generator(valid_sequence, steps=1, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./models/model6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 2, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sequence.indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_pred = np.argmax(pred[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.argmax(valid_sequence[0][1][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  66.,  66.,  66.,  66.,  66.,  66.,\n",
       "        66.,  66.,  67.,  67.,  67.,  67.,  71.,  71.,  71.,  71.,  71.,\n",
       "        71.,  71.,  71.,  69.,  69.,  69.,  69.,  67.,  67.,  67.,  67.,\n",
       "        66.,  66.,  66.,  66.,  64.,  64.,  64.,  64.,  67.,  67.,  67.,\n",
       "        67.,  67.,  67.,  67.,  67.,  66.,  66.,  66.,  66.,  64.,  64.,\n",
       "        64.,  64.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  66.,  66.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,\n",
       "        60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  62.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        62.,  62.,  60.,  60.,  60.,  60.,  62.,  62.,  62.,  62.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        57.,  57.,  57.,  57.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,\n",
       "        59.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  67.,\n",
       "        67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  60.,  60.,  60.,\n",
       "        60.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  63.,  63.,\n",
       "        63.,  63.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,   0.,   0.,   0.,   0.,  57.,  57.,  57.,\n",
       "        57.,  65.,  65.,  65.,  65.,  65.,  65.,  65.,  65.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  62.,  62.,  62.,  62.,  67.,  67.,  67.,  67.,\n",
       "        66.,  66.,  66.,  66.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,\n",
       "        64.,  66.,  66.,  66.,  66.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,  67.,\n",
       "        67.,  67.,  67.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,\n",
       "        67.,  67.,  67.,  67.,  66.,  66.,  66.,  66.,  66.,  66.,  66.,\n",
       "        66.,  67.,  67.,  67.,  67.,  67.,  67.,  66.,  66.,  64.,  64.,\n",
       "        62.,  62.,  60.,  60.,  59.,  59.,  60.,  60.,  60.,  60.,  60.,\n",
       "        60.,  60.,  60.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        59.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,\n",
       "        59.,  60.,  60.,  60.,  60.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  64.,\n",
       "        64.,  64.,  64.,  65.,  65.,  65.,  65.,  67.,  67.,  65.,  65.,\n",
       "        64.,  64.,  62.,  62.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
       "        60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  65.,  65.,\n",
       "        65.,  65.,  65.,  65.,  65.,  65.,  65.,  65.,  65.,  65.,  62.,\n",
       "        62.,  62.,  62.,  60.,  60.,  60.,  60.,  57.,  57.,  57.,  57.,\n",
       "        59.,  59.,  59.,  59.,  59.,  59.,  62.,   0.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,   0.,   0.,   0.,   0.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  66.,  66.,  66.,  66.,  67.,  67.,  67.,  67.,\n",
       "        67.,  67.,  66.,  66.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  64.,  64.,  64.,  64.,\n",
       "        62.,  62.,  62.,  62.,  60.,  60.,  60.,  60.,  62.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  60.,  60.,  59.,  59.,  59.,  59.,\n",
       "        57.,  57.,  57.,  57.,  59.,  59.,  59.,  59.,  59.,  59.,  59.,\n",
       "        59.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  69.,  69.,\n",
       "        69.,  69.,  69.,  69.,  67.,  67.,  66.,  66.,  66.,  66.,  64.,\n",
       "        64.,  64.,  64.,  66.,  66.,  66.,  66.,  66.,  66.,  66.,  66.,\n",
       "        64.,  64.,  64.,  64.,  59.,  59.,  59.,  59.,  61.,  61.,  61.,\n",
       "        61.,  61.,  61.,  61.,  61.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        60.,  60.,  59.,  59.,  59.,  59.,  55.,  55.,  55.,  55.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        64.,  64.,  64.,  64.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        59.,  59.,  59.,  59.,  67.,  67.,  67.,  67.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  66.,  66.,  66.,  66.,  67.,  67.,\n",
       "        67.,  67.,  69.,  69.,  69.,  69.,  66.,  66.,  66.,  66.,  64.,\n",
       "        64.,  64.,  64.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,   0.,   0.,   0.,   0.,  59.,  59.,  59.,\n",
       "        59.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  62.,  62.,\n",
       "        62.,  62.,  62.,  62.,  62.,  62.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  66.,  66.,  66.,  66.,  67.,  67.,  67.,\n",
       "        67.,  67.,  67.,  67.,  67.,  65.,  65.,  65.,  65.,  65.,  65.,\n",
       "        65.,  65.,   0.,   0.,   0.,   0.,  59.,  59.,  59.,  59.,  60.,\n",
       "        60.,  60.,  60.,  60.,  60.,  62.,  62.,  64.,  64.,  64.,  64.,\n",
       "        69.,  69.,  69.,  69.,  69.,  69.,  67.,  67.,  65.,  65.,  64.,\n",
       "        64.,  62.,  62.,  62.,  62.,  62.,  62.,  64.,  64.,  65.,  65.,\n",
       "        65.,  65.,  65.,  65.,  65.,  65.,  64.,  64.,  64.,  64.,  64.,\n",
       "        64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.,  64.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes + (notes > 1) * (min_pitch - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_valid[0][2] - (notes + (notes > 1) * (min_pitch - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
