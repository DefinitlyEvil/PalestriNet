{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:48<00:00, 121.91it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [09:24<00:00, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = [\n",
    "    (np.load('./data/{}_meta.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1\n",
    "idx_slur = 0\n",
    "idx_beat = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SEQUENCE_STEPS = 4  # The number of windows to look at; 4 * 32 means we look at an 8-bar window\n",
    "window_size = 32  # each measure is 16, so 32 is a two-measure window\n",
    "n_features = n_notes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes + 1\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch)\n",
    "            y[i, note_idx + 1] = 1\n",
    "        else:\n",
    "            y[i, 0] = 1 # it's a rest\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_slur(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    return meta[voice, :, idx_slur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size, max_voices=None):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "\n",
    "    score_padding = np.zeros((score.shape[0], padding_size))\n",
    "    return np.hstack((score_padding, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_beat(meta, voice):\n",
    "    return meta[voice, :, idx_beat:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, meta, voice, sequence_steps=16, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    # First, do the notes channel\n",
    "    padded_score = make_padded(score, window_size) / max_pitch\n",
    "    padding_size = window_size - 1\n",
    "    \n",
    "    # Now, the slurs channel\n",
    "    padded_meta = make_padded(meta[:, :, 0], window_size)\n",
    "    \n",
    "    # A mask showing which voice to predict\n",
    "    voice_mask = np.zeros(padded_meta.shape)\n",
    "    \n",
    "    # Stack them together\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    stacked = np.stack((padded_score, padded_meta, voice_mask), axis=-1)\n",
    "    \n",
    "    # Make the sliding windows\n",
    "    sequence = stacked.swapaxes(0, 1)[indexer, :, :]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    sequence[:, -1, voice, :2] = 0\n",
    "    \n",
    "    # Set a flag in the voice mask to indicate which voice is to be predicted\n",
    "    sequence[:, -1, voice, 2] = 1\n",
    "    \n",
    "    return sequence.reshape((score.shape[1], -1, conv_window_size, padded_score.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid, meta_train, meta_valid = train_test_split(scores, meta, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 16, 32, 5, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence(scores_valid[0], meta_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSequence(Sequence):\n",
    "    def __init__(self, scores, meta, subsample_voices=False):\n",
    "        self.scores = scores\n",
    "        self.meta = meta\n",
    "        if subsample_voices:\n",
    "            # Take one randomly sampled voice for each score\n",
    "            voice_sample = [\n",
    "                np.random.randint(score.shape[0]) \n",
    "                for score in scores\n",
    "            ]\n",
    "            self.indices = [\n",
    "                (score_idx, voice_sample[score_idx])\n",
    "                for score_idx, score in enumerate(scores)\n",
    "            ]\n",
    "        else:\n",
    "            self.indices = [\n",
    "                (score_idx, voice_idx)\n",
    "                for score_idx, score in enumerate(scores)\n",
    "                for voice_idx in range(score.shape[0])\n",
    "            ]\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        score_idx, voice = self.indices[idx]\n",
    "        score = self.scores[score_idx]\n",
    "        meta = self.meta[score_idx]\n",
    "        return (\n",
    "            [\n",
    "                make_input_sequence(score, meta, voice, sequence_steps=SEQUENCE_STEPS, conv_window_size=window_size),\n",
    "                make_input_beat(meta, voice)\n",
    "            ],\n",
    "            [\n",
    "                make_targets(score, voice),\n",
    "                make_targets_slur(meta, voice)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sequence = BatchSequence(scores_valid, meta_valid, subsample_voices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = BatchSequence(scores_train, meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.activations import relu\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_lst_m2d_1_input (InputLaye (None, None, 32, Non 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, None, 32, Non 40448       conv_lst_m2d_1_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, None, 16, Non 0           conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 16, None, 64) 221440      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           global_average_pooling2d_1[0][0] \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          8100        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 59)           5959        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 276,048\n",
      "Trainable params: 276,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "notes_model = Sequential()\n",
    "notes_model.add(layers.ConvLSTM2D(32, 3, return_sequences=True, padding='same', input_shape=(None, window_size, None, 3)))\n",
    "notes_model.add(layers.MaxPool3D(2, 2))\n",
    "notes_model.add(layers.ConvLSTM2D(64, 3, padding='same'))\n",
    "notes_model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "beats_input = layers.Input(shape=(16,))\n",
    "\n",
    "features = layers.concatenate([notes_model.output, beats_input])\n",
    "\n",
    "fc_1 = layers.Dense(100, activation='relu')(features)\n",
    "dropout = layers.Dropout(0.1)(fc_1)\n",
    "\n",
    "output_notes = layers.Dense(n_notes + 1, activation='softmax')(dropout)\n",
    "output_slur = layers.Dense(1, activation='sigmoid')(fc_1)\n",
    "\n",
    "model = Model(inputs=[notes_model.input, beats_input], outputs=[output_notes, output_slur])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=['categorical_crossentropy', 'binary_crossentropy'], metrics=['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model6.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25420"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_sequence)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_steps = len(valid_sequence)\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no compatible weights found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_weights('./models/model6.hdf5')\n",
    "except (OSError, ValueError):\n",
    "    print('no compatible weights found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "25419/25420 [============================>.] - ETA: 0s - loss: 1.4468 - dense_2_loss: 1.2840 - dense_3_loss: 0.1628 - dense_2_acc: 0.5721 - dense_2_top3_acc: 0.8383 - dense_3_acc: 0.9296 - dense_3_top3_acc: 1.0000Epoch 00003: val_loss improved from 1.63119 to 1.20589, saving model to ./models/model6.hdf5\n",
      "25420/25420 [==============================] - 9015s 355ms/step - loss: 1.4468 - dense_2_loss: 1.2840 - dense_3_loss: 0.1628 - dense_2_acc: 0.5721 - dense_2_top3_acc: 0.8383 - dense_3_acc: 0.9296 - dense_3_top3_acc: 1.0000 - val_loss: 1.2059 - val_dense_2_loss: 1.0471 - val_dense_3_loss: 0.1588 - val_dense_2_acc: 0.6711 - val_dense_2_top3_acc: 0.8911 - val_dense_3_acc: 0.9310 - val_dense_3_top3_acc: 1.0000\n",
      "Epoch 4/5\n",
      " 6403/25420 [======>.......................] - ETA: 1:50:22 - loss: 1.3610 - dense_2_loss: 1.2067 - dense_3_loss: 0.1543 - dense_2_acc: 0.5981 - dense_2_top3_acc: 0.8561 - dense_3_acc: 0.9322 - dense_3_top3_acc: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_sequence,\n",
    "    steps_per_epoch=len(train_sequence),\n",
    "    epochs=5,\n",
    "    validation_data=valid_sequence,\n",
    "    validation_steps=len(valid_sequence),\n",
    "    callbacks=[checkpointer],\n",
    "    use_multiprocessing=True,\n",
    "    initial_epoch=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 2.13 s, total: 14 s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%time pred = model.evaluate_generator(valid_sequence, steps=250, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.5010256566241225,\n",
       " 2.3594061004592399,\n",
       " 7.1416196074123679,\n",
       " 0.40318950941123771,\n",
       " 0.67477439166924746,\n",
       " 0.36416450406947215,\n",
       " 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./models/model6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_pred = np.argmax(pred[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.argmax(valid_sequence[0][1][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes + (notes > 1) * (min_pitch - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_valid[0][2] - (notes + (notes > 1) * (min_pitch - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
