{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "import preprocessing\n",
    "import score_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading score tensors from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:00<00:00, 2959.26it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = preprocessing.get_score_tensors(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata tensors from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:00<00:00, 1624.36it/s]\n"
     ]
    }
   ],
   "source": [
    "metas = preprocessing.get_metadata_tensors(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 720, 18)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = np.hstack(np.asarray([np.ravel(score) for score in scores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3257408,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pitch = 31.0\n",
    "max_pitch = 88.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 4, 32, 5, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.make_input_sequence(scores[0], metas[0], 0, max_pitch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_lst_m2d_2_input (InputLaye (None, None, 32, Non 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, None, 32, Non 40448       conv_lst_m2d_2_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, None, 16, Non 0           conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)     (None, 16, None, 64) 221440      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv_lst_m2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           global_average_pooling2d_1[0][0] \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 80)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          8100        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 59)           5959        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 276,048\n",
      "Trainable params: 276,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.conv2dlstm_model()\n",
    "model.load_weights('./weights/conv2dlstm.weights.best.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_length = 4 * 16  # let's start with 4 bars\n",
    "score_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model is conditioned on a fixed beat pattern\n",
    "beats = np.zeros((score_length, 16))\n",
    "for i in range(score_length):\n",
    "    beats[i, i % 16] = 1\n",
    "beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first try a score with 5 voices\n",
    "n_voices = 5\n",
    "sequence_steps = 4\n",
    "window_size = 32\n",
    "gibbs_steps = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_softmax(preds, temperature=1.0):\n",
    "    # taken from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = preds.astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_softmax_multi(preds, temperature=1.0):\n",
    "    # taken from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = preds.astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds, axis=1).reshape((-1, 1))\n",
    "    probas = np.apply_along_axis(lambda pred: np.random.multinomial(1, pred, 1), 1, preds)\n",
    "    return probas.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros((n_voices, score_length))\n",
    "meta = np.zeros((n_voices, score_length, 18))\n",
    "for i in range(n_voices):\n",
    "    meta[i, :, 2:] = beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_1(n_voices, score_length, gibbs_steps, temperature):\n",
    "    score = np.zeros((n_voices, score_length))\n",
    "    meta = np.zeros((n_voices, score_length, 18))\n",
    "    beats = np.zeros((score_length, 16))\n",
    "    for i in range(score_length):\n",
    "        beats[i, i % 16] = 1\n",
    "    for i in range(n_voices):\n",
    "        meta[i, :, 2:] = beats\n",
    "    for step in tqdm(range(gibbs_steps)):\n",
    "        for time_step in range(score_length):\n",
    "            for voice in range(n_voices):\n",
    "                input_ = preprocessing.make_input_sequence(score, meta, voice, max_pitch)\n",
    "                note, slur = model.predict([\n",
    "                    input_[time_step:time_step+1], beats[time_step:time_step+1]])\n",
    "                sampled_note = sample_softmax(note[0], temperature)\n",
    "                slur_proba = np.squeeze(np.array([1 - slur[0], slur[0]]))\n",
    "                sampled_slur = sample_softmax(slur_proba, temperature)\n",
    "                if sampled_note > 0:\n",
    "                    score[voice, time_step] = sampled_note + min_pitch - 1\n",
    "                else:\n",
    "                    meta[voice, time_step, score_utils.idx_rest] = 1\n",
    "                meta[voice, time_step, score_utils.idx_slur] = sampled_slur\n",
    "    return score, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_2(n_voices, score_length, gibbs_steps, temperature):\n",
    "    score = np.random.choice(all_notes, size=(n_voices, score_length))\n",
    "    meta = np.zeros((n_voices, score_length, 18))\n",
    "    beats = np.zeros((score_length, 16))\n",
    "    for i in range(score_length):\n",
    "        beats[i, i % 16] = 1\n",
    "    for i in range(n_voices):\n",
    "        meta[i, :, 2:] = beats\n",
    "    for step in tqdm(range(gibbs_steps)):\n",
    "        for voice in range(n_voices):\n",
    "            input_ = preprocessing.make_input_sequence(score, meta, voice, max_pitch)\n",
    "            note, slur = model.predict([\n",
    "                input_, beats])\n",
    "            sampled_notes = np.squeeze(sample_softmax_multi(note, temperature))\n",
    "            slur_proba = np.hstack([1 - slur, slur])\n",
    "            sampled_slurs = np.squeeze(sample_softmax_multi(slur_proba, temperature))\n",
    "            \n",
    "            score[voice] = sampled_notes + ((sampled_notes > 1) * (min_pitch - 1))\n",
    "            meta[voice, :, score_utils.idx_rest] = sampled_notes == 0\n",
    "            meta[voice, :, score_utils.idx_slur] = sampled_slurs\n",
    "    return score, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conditioned(score_template, meta_template, voices, gibbs_steps, temperature):\n",
    "    score = np.zeros(score_template.shape)\n",
    "    meta = np.zeros(meta_template.shape)\n",
    "    \n",
    "    for voice in range(score.shape[0]):\n",
    "        if voice not in voices:\n",
    "            score[voice] = score_template[voice]\n",
    "            meta[voice] = meta_template[voice]\n",
    "        \n",
    "    for time_step in tqdm(range(score.shape[1])):\n",
    "        for _ in range(gibbs_steps):\n",
    "            for voice in voices:\n",
    "                input_ = preprocessing.make_input_sequence(\n",
    "                    score, meta, voice, max_pitch)\n",
    "                beats = preprocessing.make_input_beat(meta, voice)\n",
    "                note, slur = model.predict([\n",
    "                    input_[time_step:time_step+1], beats[time_step:time_step+1]])\n",
    "                sampled_note = sample_softmax(note[0], temperature)\n",
    "                slur_proba = np.squeeze(np.array([1 - slur[0], slur[0]]))\n",
    "                sampled_slur = sample_softmax(slur_proba, temperature)\n",
    "                if sampled_note > 0:\n",
    "                    score[voice, time_step] = sampled_note + min_pitch - 1\n",
    "                else:\n",
    "                    meta[voice, time_step, score_utils.idx_rest] = 1\n",
    "                meta[voice, time_step, score_utils.idx_slur] = sampled_slur\n",
    "    return score, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conditioned_2(score_template, meta_template, voices, gibbs_steps, temperature):\n",
    "    score = np.zeros(score_template.shape)\n",
    "    meta = np.zeros(meta_template.shape)\n",
    "    \n",
    "    for voice in range(score.shape[0]):\n",
    "        if voice not in voices:\n",
    "            score[voice] = score_template[voice]\n",
    "            meta[voice] = meta_template[voice]\n",
    "            \n",
    "    for _ in tqdm(range(gibbs_steps)):\n",
    "        for voice in voices:\n",
    "            input_ = preprocessing.make_input_sequence(score, meta, voice, max_pitch)\n",
    "            beats = preprocessing.make_input_beat(meta, voice)\n",
    "            note, slur = model.predict([\n",
    "                input_, beats])\n",
    "            sampled_notes = np.squeeze(sample_softmax_multi(note, temperature))\n",
    "            slur_proba = np.hstack([1 - slur, slur])\n",
    "            sampled_slurs = np.squeeze(sample_softmax_multi(slur_proba, temperature))\n",
    "            \n",
    "            score[voice] = sampled_notes + ((sampled_notes > 1) * (min_pitch - 1))\n",
    "            meta[voice, :, score_utils.idx_rest] = sampled_notes == 0\n",
    "            meta[voice, :, score_utils.idx_slur] = sampled_slurs\n",
    "    return score, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "100%|██████████| 500/500 [00:39<00:00, 12.64it/s]\n"
     ]
    }
   ],
   "source": [
    "score, meta = sample_2(4, 64, 500, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score, meta = sample_2(scores[0], metas[0], [1], 50, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 2 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-4bb888d10c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_input_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m88.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_input_beat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslurs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PalestriNet/preprocessing.py\u001b[0m in \u001b[0;36mmake_input_sequence\u001b[0;34m(score, meta, voice, max_pitch, sequence_steps, conv_window_size)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Now, mask out the target values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# Set a flag in the voice mask to indicate which voice is to be predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 2 with size 4"
     ]
    }
   ],
   "source": [
    "idx = -1\n",
    "voice = 4\n",
    "a = preprocessing.make_input_sequence(scores[idx], metas[idx], voice, 88.0)\n",
    "b = preprocessing.make_input_beat(metas[idx], voice)\n",
    "notes, slurs = model.predict([a, b])\n",
    "n = np.argmax(notes, axis=-1)\n",
    "np.mean(scores[idx][voice] == (n + ((n > 1) * (min_pitch - 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n + ((n > 1) * (min_pitch - 1))) - scores[idx][voice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.\n",
      "   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "   7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.\n",
      "   6.5  7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5\n",
      "   6.   6.5  7.   7.5]\n",
      " [ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.\n",
      "   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "   7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.\n",
      "   6.5  7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5\n",
      "   6.   6.5  7.   7.5]\n",
      " [ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.\n",
      "   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "   7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.\n",
      "   6.5  7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5\n",
      "   6.   6.5  7.   7.5]\n",
      " [ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.\n",
      "   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "   7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.\n",
      "   6.5  7.   7.5  0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5\n",
      "   6.   6.5  7.   7.5]]\n"
     ]
    }
   ],
   "source": [
    "music = score_utils.tensor_to_score(score, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Score 0x7f374d45a860>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv207818'></div>\n",
       "                <link rel=\"stylesheet\" href=\"http://artusi.xyz/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': 'http://artusi.xyz/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv207818');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQAEBABNVHJrAAAAcwD/AwAA4ABAiACQO1qEAIA7ALwAkDpaiACAOgCYAJA3WqAAgDcAAJAzWpAAgDMAAJAwWpAAgDAAAJA8WpAAgDwAAJA1WpAAgDUAAJA8WpAAgDwAAJA+WpAAgD4AAJAzWpAAgDMAAJA6WpAAgDoAiAD/LwBNVHJrAAAAVwD/AwAA4ABAqACQNVqMAIA1AJQAkC1aoACALQAAkCtaoACAKwAAkC5asACALgAAkDBakACAMAAAkDNakACAMwAAkDBaiACAMAAAkC1aqACALQCIAP8vAE1UcmsAAABgAP8DAADgAEDIAJApWqAAgCkAAJArWqAAgCsAAJArWqwAgCsAhACQLlqQAIAuAACQLFqQAIAsAACQM1qQAIAzAACQM1qQAIAzAACQMFqMAIAwAACQLVqEAIAtAIgA/y8ATVRyawAAAFgA/wMAAOAAQMgAkC1aoACALQAAkDdahACANwCcAJAsWpAAgCwAAJAsWqAAgCwAAJAsWpAAgCwAkACQMFqQAIAwAACQK1qQAIArAACQMFqQAIAwAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "music.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[2, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
