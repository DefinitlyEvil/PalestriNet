{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Iterator, Generator\n",
    "\n",
    "# import music21\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "score_names = np.load('./data/score_names.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5930/5930 [00:09<00:00, 637.33it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = [\n",
    "    (np.load('./data/{}.npy'.format(i)))\n",
    "    for i in tqdm(range(len(score_names)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pitch = np.max([np.max(t) for t in scores])\n",
    "min_pitch = np.min([np.min(t[t > 0]) for t in scores])\n",
    "n_notes = int(max_pitch - min_pitch) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(score, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    n_output_features = n_notes\n",
    "    y = np.zeros((score.shape[1], n_output_features))  # shape: n timesteps X m features\n",
    "    for i, note in enumerate(score[voice]):\n",
    "        if note > 0:\n",
    "            note_idx = int(note - min_pitch)\n",
    "            y[i, note_idx] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_meta(meta, voice):\n",
    "    \"\"\"\n",
    "    Make our target variables. It is the a stream of notes and one of metadata\n",
    "    for a specified voice in the score.\n",
    "    \"\"\"\n",
    "    y_meta = np.zeros((meta.shape[1], 2)) #  add 2 meta features: slur, rest\n",
    "    for i in range(meta.shape[1]):\n",
    "        y_meta[i, idx_rest] = meta[voice, i, idx_rest]\n",
    "        y_meta[i, idx_slur] = meta[voice, i, idx_slur]\n",
    "    return y_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded(score, window_size, max_voices=6):\n",
    "    # pad the beginning of the sequence so that our first window ends on the first timestep\n",
    "    # also padd the voices\n",
    "    padding_size = window_size - 1\n",
    "    if max_voices is not None:\n",
    "\n",
    "        voices_padding_size = max_voices - score.shape[0]\n",
    "        voices_padding = np.zeros((voices_padding_size, score.shape[1]))\n",
    "        score = np.vstack((score, voices_padding))\n",
    "        score_padding = np.zeros((max_voices, padding_size))\n",
    "    else:\n",
    "        score_padding = np.zeros((score.shape[0], padding_size))\n",
    "    return np.hstack((score_padding, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_meta(meta, window_size):\n",
    "    padding_size = window_size - 1\n",
    "    meta_padding = np.zeros((meta.shape[0], padding_size, meta.shape[2]))\n",
    "    return np.hstack((meta_padding, meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(score, voice, sequence_steps=16, conv_window_size=32):\n",
    "    \"\"\"\n",
    "    Make an input sequence for a particular voice\n",
    "    \"\"\"\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    padded_score = make_padded(score, window_size)\n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    score_sequence = padded_score.T[indexer, :, None]\n",
    "\n",
    "    # Now, mask out the target values\n",
    "    score_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return score_sequence.reshape((score.shape[1], -1, conv_window_size, padded_score.shape[0], 1)) / max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence_meta(meta, voice, sequence_steps=16, conv_window_size=32):\n",
    "    window_size = sequence_steps * conv_window_size\n",
    "    padded_meta = make_padded_meta(meta, window_size)\n",
    "    \n",
    "    padding_size = window_size - 1\n",
    "    indexer = np.arange(window_size)[None, :] + np.arange(padded_score.shape[1] - padding_size)[:, None]\n",
    "    meta_sequence = np.swapaxes(padded_meta, 0, 1)[indexer, :, :]\n",
    "    \n",
    "    # Now, mask out the target values\n",
    "    meta_sequence[:, -1, voice, :] = 0\n",
    "    \n",
    "    return meta_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train, scores_valid = train_test_split(scores, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 880)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SEQUENCE_STEPS = 4\n",
    "window_size = 32\n",
    "n_features = 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = cycle(\n",
    "    (make_input_sequence(score, voice, sequence_steps=SEQUENCE_STEPS), make_targets(score, voice))\n",
    "    for score in scores_train\n",
    "    for voice in range(score.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 16, 32, 6, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_sequence(scores_valid[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = cycle(\n",
    "    (make_input_sequence(score, voice, sequence_steps=SEQUENCE_STEPS), make_targets(score, voice))\n",
    "    for score in scores_valid\n",
    "    for voice in range(score.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 4, 32, 6, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_gen)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Conv2D, TimeDistributed, Input, Activation, Flatten, LSTM, CuDNNLSTM, ConvLSTM2D, Dense, Dropout, MaxPool2D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "from keras.activations import relu\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_56 (TimeDis (None, 4, 32, 6, 32)      320       \n",
      "_________________________________________________________________\n",
      "time_distributed_57 (TimeDis (None, 4, 32, 6, 32)      9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_58 (TimeDis (None, 4, 16, 3, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_59 (TimeDis (None, 4, 16, 3, 64)      18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_60 (TimeDis (None, 4, 8, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_61 (TimeDis (None, 4, 8, 2, 128)      73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, 4, 8, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_63 (TimeDis (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 58)                7482      \n",
      "=================================================================\n",
      "Total params: 372,570\n",
      "Trainable params: 372,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu'), input_shape=(SEQUENCE_STEPS, window_size, 6, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "# model.add(TimeDistributed(Conv2D(64, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(64, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPool2D(2, 2, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(128, 3, padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.1)))\n",
    "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "model.add(LSTM(128, return_sequences=True, unroll=True, dropout=0.1))\n",
    "model.add(LSTM(128, dropout=0.1, unroll=True))\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(n_features, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='./models/model5.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25420"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = np.sum(score.shape[0] for score in scores_train)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2835"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_steps = np.sum(score.shape[0] for score in scores_valid)\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no weights found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_weights('./models/model5.hdf5')\n",
    "except OSError:\n",
    "    print('no weights found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  228/25420 [..............................] - ETA: 1:19:51 - loss: 2.8916 - acc: 0.0475 - top3_acc: 0.1559"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_gen, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
